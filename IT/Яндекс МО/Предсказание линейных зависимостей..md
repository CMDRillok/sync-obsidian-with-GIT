[[машинное обучение]] построено на простой идее: мы скармливаем программе много примеров данных([[данные]]), чтобы она нашла закономерности между ними.

Например, [[модель ии]], которая нашла закономерности в человеческой речи, может ее имитировать — и генерировать страшные послания...

Или представь: ты занимаешься продажей квартир. Для этого хорошо бы очень точно понимать изменения средних цен на рынке. Ты можешь предположить самостоятельно, посмотрев на историю изменений, но чем точнее твое предсказание — тем больше денег ты получишь. Значит, оно должно быть **очень точным**.

Поэтому имеет смысл построить модель машинного обучения. Ты можешь дать ей свою приблизительную функцию цены от времени, а модель доведет ее до идеала!

В этом занятии мы создадим модель МО, которая по примерам данных строит **линейную функцию зависимости — то есть, прямую.**([[линейная зависимость]])

Задача построения общей функции по отдельным данным называется регрессией([[регрессия]]). А так как наша функция линейна, то это будет...
## Задача линейной регрессии
Представь: тебя заперли в глуши, без интернета и доступа к миру, вместе с двумя людьми, которые отчаянно ругаются между собой, размахивая градусниками. Один из них измеряет температуру в градусах Цельсия, второй — в градусах Фаренгейта. Примирить их можно, только разъяснив им формулу перевода — но откуда ее взять?

Давай создадим модель МО, которая вычислит ее за нас!

Ладно: вряд ли ты окажешься в такой нелепой ситуации. Но пример с термометрами удобен нам тем, что мы можем сравнить работу модели с реальной функцией перевода. Значит, мы сможем в процессе определять ее точность.
Итак, у тебя есть два термометра, но оба измеряют температуру **с ошибками**.

Ты предполагаешь, что связь между градусами Цельсия и Фаренгейта линейна — то есть, описывается формулой прямой `F = kC + b`.

**Решение №1: математическое**

Померяем температуру утром и вечером:
![[Pasted image 20250818135304.png]]
Мы знаем, что зависимость линейная. Значит, эта задача превращается в задачу «провести прямую через две точки»:
![[Pasted image 20250818135325.png]]

Ее можно решить обычной математикой!

Подставив наши точки в уравнение `F = k*C + b`, получим систему уравнений:

```
54 = 12*k + b
64 = 18*k + b
```

У нее есть ровно одно решение: `k = 5/3, b = 34`.

Получили ли мы правильный ответ?

Выведенная формула перевода выглядит так: `y = 5/3*x + 34`. Но реальная формула от нее отличается: `y = 9/5*x + 32`.

Посмотрим на эти две прямые на графике:
![[Pasted image 20250818135348.png]]
Что же пошло не так?

А дело в том, что градусники, которыми мы замеряли температуру, показывают неточные данные. 12°C — это 53.6°F, а наш термометр округлил это значение до 54 градусов. А 18°C — это 64.4°F, а не 64°F.

И если мы попробуем перевести 0°C, то по нашей шкале мы получим 34°F, а по реальной — 32°F. Два градуса разницы - не очень-то хорошо!

Чтобы сделать предсказание точнее, можно собрать побольше измерений. Но математическое решение уже не подойдет! Из-за погрешностей через большой набор точек уже нельзя будет провести прямую.

Теперь перед нами стоит другая задача: провести прямую так, чтобы она была как можно ближе к нашим точкам.

---

Но как оценить, какая прямая будет самой близкой? Здесь нам поможет...

## Измерение ошибки

Что означает «прямая проведена как можно ближе к точкам»?

Чтобы это оценить, можно для каждой проведенной прямой считать **ошибку**: как далеко от нее находятся точки. Найдем формулу ошибки →︎ отыщем минимум этой функции → получим самую точную прямую. Профит!

Как же нам считать ошибку?

Например, можно вычислять расстояние от каждой точки до прямой по оси Y:
![[Pasted image 20250818135412.png]]
Чем меньше суммарное расстояние — тем меньше ошибка. Метрика [[MAE (mean absolute error, средняя ошибка по модулю)]] 

Высчитывая формулу ошибки, мы сможем сравнивать, какая прямая лучше. Например:
![[Pasted image 20250818135441.png]]
Прямая 1 (синяя), судя по значению MAE, выигрывает.

Кроме MAE, на графике указана другая метрика: [[MSE (mean squared error, средняя квадратичная ошибка)]]. 

Открой [симулятор вычисления ошибки](https://yastatic.net/s3/lyceum/files/7c4c93ed-2eff-4b7b-85fa-f78444e25b90/upload.html) и посмотри, как меняются значения MAE и MSE на разных прямых.

Метрики MAE и MSE показывают разницу между прямыми одинаково: если MAE будет больше для какой-то прямой, то и MSE. Но мы будем использовать MSE: у нее удобнее брать производную.

Итак, мы создали функцию ошибки. Осталось минимизировать ее, и мы получим самую точную прямую!

---

**Итоговый алгоритм поиска зависимости:**

- Провести приблизительную прямую
- Посчитать функцию ошибки (например, MAE или MSE)
- Двигать прямую, уменьшая ошибку
- Получить самую точную прямую для минимальной ошибки


Для каждой потенциальной прямой связи градусов Цельсия и Фаренгейта `F = kC + b` мы научились считать ошибку — с помощью метрики MSE. Теперь осталось минимизировать эту ошибку!

Построенная MSE будет похожа на параболу. Значит, мы можем использовать метод градиентного спуска([[Градиентный спуск]]) для поиска минимума.

Чтобы вспомнить, как работает градиентный спуск, открой [тренажер](https://yastatic.net/s3/lyceum/files/540bb236-9fb0-463e-971f-21050187e6cb/upload.html).
## Практическая реализация
Можно самостоятельно считать MSE и реализовывать градиентный спуск, вычисляя производную... а можно выбрать счастье и использовать проверенный код, который уже написали до нас.

Все, что нужно для линейной регрессии, уже реализовано в библиотеке [[sklearn]]. Подключим нужные функции:
```python
from sklearn.linear_model import LinearRegression # класс модели линейной регрессии
from sklearn.metrics import mean_squared_error # функция MSE
```
Теперь нам нужны [[данные]] для обучения. Чтобы не бегать по улице с градусниками — нам, все-таки, нужно учебную модель проверить, а не реальную задачу решить, — сгенерируем 20 точек и добавим в них ошибку.

Ошибка будет достаточно большая: ±3°F. В реальной жизни вышло бы поменьше, но так будет нагляднее.
```python
# импортируем numpy
import numpy as np

# делаем генерацию случайных чисел неслучайной, чтобы результат выполнения программы не менялся
np.random.seed(42)

# создаем массив из 20 точек от -20°C до 40°C
C = np.linspace(-20, 40, 20) 
# создаем соответствующие правильные значения по Фаренгейту — по ним будем проверять
F_ideal = 1.8 * C + 32 

# создаем случайную погрешность
noise = np.random.normal(0, 3, size=len(C))
# добавляем погрешность к градусам Фаренгейта
F_real = F_ideal + noise
```
Посмотрим, как данные с шумом (погрешностью) отличаются от реальной прямой зависимости?

Давай покажем это на [[график]]е:
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(C, F_real, label='Измерения с шумом') # сгенерированные точки
plt.plot(C, F_ideal, 'g--', label='Идеальная формула') # прямая
plt.xlabel('Температура (°C)')
plt.ylabel('Температура (°F)')
plt.title('Зависимость °F от °C')
plt.legend()
plt.grid(True)
plt.show()
```
![[Pasted image 20250818140837.png]]
```python
# превращаем C в матрицу из одного столбца — модель принимает только такой формат
C = C.reshape(-1, 1)

# создаем модель
model = LinearRegression()
# обучаем модель
model.fit(C, F_real)

# получаем коэффициенты
k = model.coef_[0]
b = model.intercept_
print(f"Полученная формула: F = {k:.2f}*C + {b:.2f}")
print(f"Идеальная формула:  F = 1.80*C + 32.00")

# вывод:
# Полученная формула: F = 1.71*C + 32.43
# Идеальная формула:  F = 1.80*C + 32.00
```
Ура: полученная формула похожа на исходную!
Посчитаем ее ошибку:

```python
# считаем предсказанные значения
F_pred = model.predict(C)
# считаем ошибку между предсказанными и реальными значениями 
mse = mean_squared_error(F_real, F_pred)

print(f"\nСреднеквадратичная ошибка (MSE): {mse:.2f}")

# вывод:
# Среднеквадратичная ошибка (MSE): 4.91
```

Найденная минимальная ошибка MSE равна 4.91, что логично — раз у нас в данных ошибка в пределах ±3°F.
Сравним две прямые: реальную функцию зависимости и предсказанную:

```python
plt.figure(figsize=(10, 6))
plt.scatter(C, F_real, label='Измерения')
plt.plot(C, F_ideal, 'g--', label='Идеальная формула')
plt.plot(C, F_pred, 'r-', linewidth=2, label='Предсказание модели')
plt.xlabel('Температура (°C)')
plt.ylabel('Температура (°F)')
plt.title('Линейная регрессия: сравнение моделей')
plt.legend()
plt.grid(True)
plt.show()
```
![[Pasted image 20250818141100.png]]
Обе прямые довольно близки к точкам — но предсказанная даже ближе к ним, чем идеальная! Получается, мы очень точно нашли зависимость, которая описывает данные с погрешностью.

# итог
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

np.random.seed(42)  # Для воспроизводимости
C = np.linspace(-20, 40, 20)  # 20 точек от -20°C до 40°C
F_ideal = 1.8 * C + 32  # Идеальные значения без шума

# Добавляем шум (погрешность ±1°F)
noise = np.random.normal(0, 1, size=len(C))
F_real = F_ideal + noise

# Преобразуем в матрицу признаков (т.к. sklearn ожидает 2D-массив)
C = C.reshape(-1, 1)

# Обучаем модель
model = LinearRegression()
model.fit(C, F_real)

# Вычисляем предсказания
F_pred = model.predict(C)

# Вычисляем среднюю квадратичную ошибку относительно измерений
mse_real = mean_squared_error(F_real, F_pred)

# И относительно идеальной линии
mse_ideal = mean_squared_error(F_ideal, F_pred)
```
