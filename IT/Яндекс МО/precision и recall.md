Эти метрики пытаются определить точность угадывания одного конкретного класса — класса 1.

Но **precision** считает отношение правильно угаданных единиц ко всем **предсказанным** единицам, а **recall** — отношение правильно угаданных ко всем **реальным** единицам.

Например, назовем в задаче диагностики классом 1 — больных. Оценим эти метрики для модели, которая всех считает больными.

[[precision]] покажет `(правильно предсказанные больные) / (общее число предсказанных больных) = 1 / 100 = 0.01`.

А [[recall]] покажет `(правильно предсказанные больные) / (общее число реальных больных) = 1 / 1 = 1`.

То есть, если нам важно, чтобы все угаданные моделью больные были действительно больными — будем считать precision. А если важнее, чтобы модель не пропускала как можно больше больных, то подойдет recall.
Формулы метрик:
$$ 
precision = \frac{TP}{TP + TF}
$$
[[TP (True Positive)]] [[FP (False Positive)]]
$$
precision = \frac{TP}{TP + FN}
$$
[[TP (True Positive)]] [[FN (False Negative)]]
[[точность модели]]