- это качество выполненной работы машинным обучением ([[машинное обучение]])
1) для начала надо разделить [[данные]] на выборки([[обучающая выборка]] и [[тестовая выборка]]) - для проверки
	1) обычно делят в отношении 80/20
	2) 
	   ```python
# подключаем функцию, которая разбивает данные на части
from sklearn.model_selection import train_test_split

# разбиваем данные на обучающую и тестовую выборку
# X_train, y_train — это данные и классы цветков обучающей выборки
# X_test, y_test — данные и классы цветков тестовой выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```
	3) А теперь создадим модель и обучим ее на тренировочных данных:
	```python
# подключаем функцию логистической регрессии
from sklearn.linear_model import LogisticRegression

# создаем модель и тренируем ее на обучающей выборке
model = LogisticRegression(random_state=123)
model.fit(X_train, y_train)
	```
	4) Посмотрим результат на графике. Кружки — точки из обучающей выборки, квадраты — из тестовой. Линия — разделение, которое создала модель. ![[Pasted image 20250822191152.png]]
2) Но как теперь оценить результат модели? Могли ли бы мы сделать лучше? Для этого нам нужны новые Метрики
	1) если написать другую модель, которая классифицирует([[классификация МО]]) больных редкой болезнью и здоровых, при этом соотношение здоровых и больных будет 1/99, то [[модель ии]] точна на 99%, что совершенно не верно
	2) Для оценки качества можно рассмотреть такие четыре параметра:
		- сколько раз мы правильно попали в класс 1
		- сколько раз мы неправильно попали в класс 1
		- сколько раз мы правильно попали в класс 0
		- сколько раз мы неправильно попали в класс 0
		Для примера с диагностикой эти параметры будут выглядеть так:
		- сколько раз мы назвали здоровых здоровыми
		- сколько раз мы назвали здоровых больными
		- сколько раз мы назвали больных больными
		- сколько раз мы назвали больных здоровыми
	3) Разработчики моделей часто называют класс 1 [[Positive]], а класс 0 — [[Negative]], поэтому эти четыре параметра называют [[TP (True Positive)]], [[FP (False Positive)]], [[TN (True Negative)]] и [[FN (False Negative)]].
	4) для модели-оптимиста 

| Positive (предсказали 1) | Negative (предсказали 0) |
| ------------------------ | ------------------------ |
| 99                       | 0                        |
| 1                        | 0                        |

	5) для модели-писсимиста

| Positive (предсказали 1) | Negative (предсказали 0) |
| ------------------------ | ------------------------ |
| 99                       | 0                        |
| 1                        | 0                        |
|                          |                          |
По этим таблицам можно легко увидеть, что модель-оптимистка хорошо умеет называть здоровых людей здоровыми, а модель-пессимистка — больных больными.
Есть несколько метрик, которые вычисляются по этим параметрам:
- [[accuracy]]
- [[precision]]
- [[recall]]
- [[F1-score]]
[[precision и recall]]

---
Посчитать эти метрики можно с помощью функций библиотеки [[sklearn]]:

```python
# подключаем функции метрик
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
```
Каждая [[функция]] принимает два параметра: реальные классы тестовой выборки (y_test) и предсказанные (y_pred).
Давай вычислим значения метрик для нашей модели, классифицирующей ирисы!
```python
# вычисляем значения метрик
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# выводим результат
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1: {f1:.2f}")

# вывод:
# Accuracy: 0.95
# Precision: 1.00
# Recall: 0.90
# F1: 0.95
```
Отлично! Все метрики близки к единице — значит, мы хорошо обучили модель.




