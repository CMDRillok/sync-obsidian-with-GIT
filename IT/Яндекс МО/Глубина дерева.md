- это максимальное количество вопросов, которые может задать дерево
[[рашающее дерево]] - в этом примере в [[обучающая выборка|обучающей выборке]] всего 5 пассажиров
В нашем алгоритме [[модель ии]] строит [[граф-дерево|дерево]], пока везде не достигнет нулевых метрик. Но что, если это будет очень глубокое дерево, в листьях которого опять останется по одному-двум пассажирам?
Вряд ли такое дерево показывает реальную ситуацию. Мы же хотим найти зависимости вида «скорее всего, маленькие дети, путешествовавшие с родителями, выжили», а не «Мэри Глинн, плывшая в каюте первого класса из Куинстауна, точно выжила»!
Слишком конкретные зависимости дадут очень хороший результат на тренировочных данных, но на [[тестовая выборка|тестовых]] начнут говорить неправду.
У дерева, которое построила наша модель в конце прошлого блока, глубина равна 18. Представь себе это дерево — на экран не поместится! А при том, что признаков, которые мы сравниваем, всего пять — многовато.

Чтобы дерево было оптимальным, мы можем указать модели его **максимальную глубину**.
Тогда модель остановится, дойдя до этой глубины, даже если метрики не равны нулю. Работа дерева будет менее точной на тренировочных данных, но зато — более адекватной на **тестовых!**

Максимальная глубина дерева — это [[гиперпараметр]] модели. Осталось понять, как [[подбор гиперпараметра|подобрать его значение]]