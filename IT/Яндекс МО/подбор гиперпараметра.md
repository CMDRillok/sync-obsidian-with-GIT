 [новый симулятор выживаемости на «Титанике»](https://yastatic.net/s3/lyceum/files/71c005d1-5ee1-4f1f-a108-a86ef765fd43/upload.html). Максимальную [[Глубина дерева|глубину]] можно подобрать на глаз, но лучше — сравнить разные и выбрать точно.
 Для этого обучим [[модель ии|модели]] с разными глубинами и выберем из них лучшую. В таком случае у обучения будет три этапа:
1. Создание деревьев разных глубин (скармливаем моделям [[тестовая выборка|тренировочные данные]])
2. Подбор [[гиперпараметр|гиперпараметра]] (сравниваем работу [[граф-дерево|деревьев]] на [[валидационная выборка|валидационных данных]])
3. Проверка результата дерева с лучшим гиперпараметром (на [[тестовая выборка|тестовых данных]])
Как видишь, теперь у нас не две выборки данных, а три. К ним прибавились данные для валидации — те, на которых мы будем сравнивать деревья разной длины.
---
## Реализация на Python
Для разбивки данных на три части снова используем train_test_split, но два раза подряд. Поделим данные в пропорции 60/20/20: [[sklearn]]

```python
# отделяем 20% тестовых данных
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# от оставшихся 80% отделяем четверть на валидацию (0.25 * 0.8 = 0.2, так что это 20% от всех данных) 
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=1)
```
С каким значением глубины модель работает лучше? Проверим глубины от 1 до 15 и сравним качество модели на валидационной выборке. Для этого — создадим 15 разных моделей и запишем результаты их обучения.
```python
# список с глубинами деревьев
depths = list(range(1, 16))

# список с точностями на тренировочных данных
train_acc = []

# список с точностями на данных для валидации
val_acc = []

# перебираем глубины
for d in depths:
    # создаем модель с нужной глубиной с помощью параметра max_depth
    model = DecisionTreeClassifier(max_depth=d, random_state=42)
    # обучаем на тренировочных данных
    model.fit(X_train, y_train)
    
    # точность на тренировке
    y_pred_train = model.predict(X_train)
    train_acc.append(accuracy_score(y_train, y_pred_train))
    
    # точность на валидации
    y_pred_val = model.predict(X_val)
    val_acc.append(accuracy_score(y_val, y_pred_val))
```
Нам нужно дерево с максимальной метрикой accuracy.
```python
# находим максимальную глубину
best_depth = depths[val_acc.index(max(val_acc))]
print(f"Лучшая глубина: {best_depth}, Accuracy на валидации: {max(val_acc):.2f}")
```

Лучшая глубина: 4, Accuracy на валидации: 0.81

### Как меняется accuracy в зависимости от глубины?
Нарисуем график: [[matplotlib]] 

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(depths, train_acc, label="Train Accuracy") # accuracy, посчитанная на тренировочной выборке
plt.plot(depths, val_acc, label="Validation Accuracy") # accuracy, посчитанная на выборке для валидации

# оформление графика
plt.xlabel("Depth")
plt.ylabel("Accuracy")
plt.title("Зависимость точности от глубины дерева")
plt.legend()
plt.grid(True)

# показываем график
plt.show()
```
![[image 4.png]]Кривые ведут себя по-разному. Точность на тестовой выборке растет с глубиной, а на валидационной выборке сначала растет, но потом начинает падать.
Оптимальная глубина выбрана — она равна четырем. Теперь мы можем обучить дерево с этой глубиной на всех данных, кроме тестовых, чтобы получить максимально успешный результат.

```python
# создаем модель с лучшей глубиной
final_model = DecisionTreeClassifier(max_depth=best_depth, random_state=42)

# обучаем на объединенных train + val
final_model.fit(X_train_val, y_train_val)

# оцениваем на тестовых данных
y_pred_final = final_model.predict(X_test)
print("Точность на тесте:", accuracy_score(y_test, y_pred_final))
```

Точность на тесте будет примерно 0.81!
И в отличие от предыдущих моделей, которые вычисляли математическую функцию, у дерева нам сильно проще понять смысл найденной закономерности. Вместо сложной математики — понятные для человека вопросы.