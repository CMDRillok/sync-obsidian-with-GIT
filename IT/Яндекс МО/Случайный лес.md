Мы уже умеем строить [[рашающее дерево]]. Это мощный алгоритм машинного обучения! Но есть проблема: деревья решений **часто [[переобучение модели|переобучаются]]**.

Мы решали эту проблему с помощью ограничения на [[Глубина дерева|глубину дерева]], но иногда этого недостаточно. Нам нужен другой способ, чтобы сделать [[модель ии]] более **обобщающей**.

Здесь нам на помощь приходит **случайный лес**.

---
- Случайный лес — это [[ансамблевый метод машинного обучения]]. 
- Случайный лес — это **множество деревьев решений**, которые работают вместе, чтобы классифицировать новые объекты.

Классификация происходит по такому алгоритму:
1. лес передает объект **каждому дереву** в ансамбле
2. деревья делают **свои прогнозы**
3. случайный лес выбирает **наиболее популярный класс (голосование большинством)**
Некоторые деревья в случайном лесе могут переобучиться, но коллективный мозг работает успешнее — переобучение отдельного дерева оказывает меньшее влияние на итоговый результат.

---
Давай рассмотрим на примере. Ты думаешь купить машину и хочешь создать модель, которая оценивает автомобили.

У тебя есть датасет с такими признаками:

| признак  | описание                                                               |
| -------- | ---------------------------------------------------------------------- |
| safety   | насколько автомобиль безопасен (значения: low, med, high).             |
| buying   | стоимость автомобиля (значения: low, med, high, vhigh)                 |
| maint    | стоимость технического обслуживания (значения: vhigh, high, med, low). |
| doors    | количество дверей (значения: 2, 3, 4, 5more)                           |
| persons  | количество помещающихся пассажиров (значения: 2, 4, more)              |
| lug_boot | размер багажника (значения: small, med, big)                           |
| accep    | оценка автомобиля (значения unacceptable, acceptable, good, very good) |
Загрузим [[данные]] и разделим их на [[обучающая выборка|обучающую]] и [[тестовая выборка|тестовую выборки]]: [[Pandas]] [[sklearn]]

```python
# подключаем библиотеки
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split # разбиение на выборки
from sklearn.tree import DecisionTreeClassifier # класс модели дерева
from sklearn.ensemble import RandomForestClassifier # класс модели случайного леса
from sklearn.metrics import accuracy_score # функция точности

# загружаем данные, указываем полный путь к файлу и названия нужных столбцов
df = pd.read_csv('https://yastatic.net/s3/lyceum/files/cef58ceb-187c-4104-9a90-124714292af0/upload.csv', 
                 names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])


# кодируем текстовые признаки числами и записываем в отдельную переменную
X = pd.get_dummies(df.iloc[:, 0:6], drop_first=True)

# меняем все текстовые значения результата на числа 0 или 1
# 0 — неприемлимо (unacc), 1 — все остальные (acceptable, good, very good)
df['accep'] = ~(df['accep'] == 'unacc')
y = df['accep']

# разбиваем данные на выборки
x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)
```
А теперь создадим случайный лес:

```python
# сначала обучаем простое дерево решений
dt = DecisionTreeClassifier(max_depth=5) # максимальная глубина 5
dt.fit(x_train, y_train)
y_pred_dt = dt.predict(x_test)

# оцениваем результат
print(f'Точность дерева решений: {accuracy_score(y_test, y_pred_dt)}')

# обучаем случайный лес из 5 деревьев с максимальной глубиной 5
rf = RandomForestClassifier(n_estimators=5, max_depth=5, random_state=0)
rf.fit(x_train, y_train)
y_pred_rf = rf.predict(x_test)
```
У модели случайного леса есть два важных параметра:

- max_depth — максимальная глубина каждого дерева в лесу
- n_estimators — количество деревьев в лесу

Насколько точно мы обучили лес? Проверим с помощью метрики accuracy:

```python
# оцениваем результат леса
print(f'Точность случайного леса: {accuracy_score(y_test, y_pred_rf)}')
```

Программа выведет такое:

```python
Точность дерева решений: 0.8891454965357968

Точность случайного леса: 0.8937644341801386
```

Точность предсказаний в ансамбле выше — может показаться, что ненамного, но в случае реальных данных даже доля процента может мощно повлиять на результат. Например, когда от этой доли процента зависит безопасность или здоровье людей!

![[Почему случайный лес лучше одного дерева]]

![[Почему деревья в случайном лесу дают разные предсказания]]

